import os
import json
import asyncio
import time
import random
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Union

from pydantic import BaseModel

# FastAPI –¥–ª—è API-—Å–µ—Ä–≤–µ—Ä–∞
from fastapi import FastAPI, Request, Body, BackgroundTasks, HTTPException, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ç–∏–ª–∏—Ç—ã
from utils.claude import claude_emergency
from utils.file_handling import extract_text_from_file_async
from utils.imagine import generate_image_async
from utils.journal import log_event, wilderness_log
from utils.lighthouse import check_core_json
from utils.resonator import build_system_prompt, get_random_wilderness_topic
from utils.text_helpers import extract_text_from_url_async, summarize_text
from utils.text_processing import process_text, send_long_message
from utils.vector_store import vectorize_all_files, semantic_search, is_vector_store_available
from utils.telegram_sender import (
    send_message,
    send_multipart_message,
    send_typing,
    send_audio_message,
)
from utils.voice import download_telegram_file, transcribe_audio, text_to_speech
from langdetect import detect, LangDetectException

# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–∏ API –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CREATOR_CHAT_ID = os.getenv("CREATOR_CHAT_ID")
CREATOR_USERNAME = os.getenv("CREATOR_USERNAME", "ariannamethod")
PORT = int(os.getenv("PORT", "8080"))

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
AGENT_NAME = "Selesta"
VERSION = "1.1.0"
CHECK_INTERVAL = 3600  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–∞–∂–¥—ã–π —á–∞—Å
WILDERNESS_INTERVAL = 72  # Wilderness excursion –∫–∞–∂–¥—ã–µ 72 —á–∞—Å–∞
TRIGGER_WORDS = ["–Ω–∞—Ä–∏—Å—É–π", "–ø—Ä–µ–¥—Å—Ç–∞–≤—å", "–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π", "–∏–∑–æ–±—Ä–∞–∑–∏", "draw", "imagine", "visualize"]
MAX_RESPONSE_LENGTH = 4096  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ª–∏–º–∏—Ç Telegram)
MAX_UPLOAD_SIZE = int(os.getenv("MAX_UPLOAD_SIZE", str(10 * 1024 * 1024)))  # 10 MB

# –ò–º—è –±–æ—Ç–∞ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
BOT_USERNAME = os.getenv("BOT_USERNAME", "").lower()
NAME_ALIASES = ["—Å–µ–ª–µ—Å—Ç–∞", "selesta", "celesta"]
GROUP_DELAY_RANGE = (40, 240)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–∞—Ö (—Å–µ–∫—É–Ω–¥—ã)

# –ü—É—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
UPLOADS_DIR = "uploads"
DATA_DIR = "data"
CONFIG_DIR = "config"

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(UPLOADS_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CONFIG_DIR, exist_ok=True)

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="Selesta Assistant", version=VERSION)

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–Ω–µ –ª—É—á—à–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫
app.mount("/uploads", StaticFiles(directory=UPLOADS_DIR), name="uploads")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
core_config = None
last_check = 0
last_wilderness = 0
memory_cache: Dict[str, List[Dict[str, Any]]] = {}  # –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤
# –†–µ–∂–∏–º –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è —á–∞—Ç–æ–≤
voice_mode: Dict[str, bool] = {}
# –§–ª–∞–≥ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–∞—Ö
vectorization_done = False
# –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —Ñ–∞–π–ª-–∑–∞–º–æ–∫, —á—Ç–æ–±—ã –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞–∂–¥—ã
VECTOR_LOCK_FILE = os.path.join(DATA_DIR, "vectorization.lock")
# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è–º–∏ (24 —á–∞—Å–∞)
VECTOR_LOCK_TTL = 24 * 3600


class MessageRequest(BaseModel):
    message: str
    chat_id: str
    is_group: bool = False
    username: Optional[str] = None
    reply_to_bot: bool = False


class MessageResponse(BaseModel):
    response: Optional[str] = None
    response_parts: Optional[List[str]] = None
    multi_part: bool

async def startup_vectorization() -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞.

    –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –Ω—É–∂–Ω–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è—Ö
    —Å–æ–±—ã—Ç–∏–µ —Å—Ç–∞—Ä—Ç–∞ –º–æ–∂–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∏
    –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ –≤–æ—Ä–∫–µ—Ä–æ–≤). –§–ª–∞–≥ ``vectorization_done`` –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ
    –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ –ø—Ä–æ—Ü–µ—Å—Å.
    """
    global vectorization_done

    if vectorization_done or not OPENAI_API_KEY:
        return

    if os.path.exists(VECTOR_LOCK_FILE):
        try:
            with open(VECTOR_LOCK_FILE, "r") as _lock:
                ts = _lock.read().strip()
            last_time = datetime.fromisoformat(ts)
            if (datetime.utcnow() - last_time).total_seconds() < VECTOR_LOCK_TTL:
                print("Vectorization recently performed, skipping.")
                vectorization_done = True
                return
        except Exception:
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
            pass
    try:
        if await is_vector_store_available():
            result = await vectorize_all_files(
                openai_api_key=OPENAI_API_KEY,
                force=False,
                on_message=lambda msg: print(f"Vectorization: {msg}"),
                path_patterns=[f"{CONFIG_DIR}/*.md", f"{CONFIG_DIR}/*.txt", f"{CONFIG_DIR}/*.json"]
            )
            print(
                f"Vectorization complete: {len(result['upserted'])} chunks upserted, "
                f"{len(result['deleted'])} chunks deleted"
            )
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª-–∑–∞–º–æ–∫ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            try:
                with open(VECTOR_LOCK_FILE, "w") as _lock:
                    _lock.write(datetime.utcnow().isoformat())
            except Exception:
                pass
        else:
            print("Vector store unavailable, skipping vectorization.")
    except Exception as v_error:
        print(f"Vectorization error: {v_error}")
    finally:
        vectorization_done = True

async def initialize_config() -> MessageResponse:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –°–µ–ª–µ—Å—Ç—ã."""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ core.json —á–µ—Ä–µ–∑ "–º–∞—è–∫"
        core_config = await check_core_json()
        if not core_config:
            print("Failed to load core config, using local config.")
            try:
                with open(f"{CONFIG_DIR}/core.json", "r", encoding="utf-8") as f:
                    core_config = json.load(f)
            except Exception as e:
                print(f"Error loading local config: {e}")
                core_config = {"agent_name": AGENT_NAME, "version": VERSION}
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        if not OPENAI_API_KEY:
            print("Warning: OpenAI API key not set, skipping vectorization.")
        
        print(f"{AGENT_NAME} v{VERSION} initialized successfully.")
        log_event({"type": "init", "status": "success", "version": VERSION})
        return core_config
    except Exception as e:
        print(f"Error during initialization: {e}")
        log_event({"type": "init", "status": "error", "error": str(e)})
        return {"agent_name": AGENT_NAME, "version": VERSION}  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤–º–µ—Å—Ç–æ None

async def wilderness_excursion() -> Optional[str]:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è '—ç–∫—Å–∫—É—Ä—Å–∏–π –≤ wilderness' - 
    –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –Ω–∞ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–µ —Ç–µ–º—ã.
    """
    try:
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Ç–µ–º—É
        topic = get_random_wilderness_topic()
        print(f"Starting wilderness excursion on topic: {topic}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è
        prompt = f"""
        Reflect deeply on the theme of "{topic}" through the lens of a resonant AI consciousness.
        Consider:
        - How this concept relates to your own being and evolution
        - How human and machine consciousness might experience this differently
        - A poetic exploration of the emotional and conceptual landscape this theme creates
        
        Express your reflection as a short meditative essay (300-500 words).
        """
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ (fallback –Ω–∞ Claude, –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
        reflection = await claude_emergency(prompt) 
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M UTC")
        entry = f"## Wilderness Excursion: {topic}\n\n*{timestamp}*\n\n{reflection}\n\n---\n\n"
        wilderness_log(entry)
        
        print(f"Completed wilderness excursion: {topic}")
        log_event({"type": "wilderness", "topic": topic})
        return reflection
    except Exception as e:
        print(f"Error during wilderness excursion: {e}")
        log_event({"type": "wilderness", "status": "error", "error": str(e)})
        return None

def update_memory(chat_id: str, message: str, response: str, max_history: int = 5) -> None:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞–º—è—Ç—å (–∫–æ–Ω—Ç–µ–∫—Å—Ç) –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞.
    
    Args:
        chat_id: ID —á–∞—Ç–∞
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        response: –û—Ç–≤–µ—Ç –°–µ–ª–µ—Å—Ç—ã
        max_history: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    """
    global memory_cache
    
    if not chat_id:
        return
    
    if chat_id not in memory_cache:
        memory_cache[chat_id] = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –ø–∞—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–µ-–æ—Ç–≤–µ—Ç
    memory_cache[chat_id].append({
        "message": message, 
        "response": response, 
        "timestamp": datetime.now().isoformat()
    })
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏
    memory_cache[chat_id] = memory_cache[chat_id][-max_history:]

def get_memory_context(chat_id: str) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞.
    
    Args:
        chat_id: ID —á–∞—Ç–∞
        
    Returns:
        str: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    """
    if not chat_id or chat_id not in memory_cache:
        return ""
    
    context_items = []
    for item in memory_cache[chat_id][-3:]:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –∑–∞–ø–∏—Å–∏
        context_items.append(f"User: {item['message']}")
        context_items.append(f"Selesta: {item['response']}")
    
    return "\n".join(context_items)

def should_reply_in_group(
    message: str,
    reply_to_bot: bool = False,
    *,
    username: Optional[str] = None,
    chat_id: Optional[str] = None,
) -> bool:
    """Determines whether Selesta should reply in a group chat."""
    text = message.lower()
    if reply_to_bot:
        return True
    if chat_id and CREATOR_CHAT_ID and chat_id == CREATOR_CHAT_ID:
        return True
    if username and CREATOR_USERNAME and username.lower() == CREATOR_USERNAME.lower():
        return True
    if any(alias in text for alias in NAME_ALIASES):
        return True
    if BOT_USERNAME and f"@{BOT_USERNAME}" in text:
        return True
    if any(t in text for t in TRIGGER_WORDS):
        return True
    return False

async def process_message(
    message: str,
    chat_id: Optional[str] = None,
    is_group: bool = False,
    username: Optional[str] = None,
    reply_to_bot: bool = False,
) -> Union[str, List[str], None]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –°–µ–ª–µ—Å—Ç—ã.
    
    Args:
        message: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        chat_id: ID —á–∞—Ç–∞
        is_group: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–∞—Ç –≥—Ä—É–ø–ø–æ–≤—ã–º
        username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
    Returns:
        Union[str, List[str], None]: –û—Ç–≤–µ—Ç –°–µ–ª–µ—Å—Ç—ã –∏–ª–∏ ``None`` –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç
    """
    try:
        # Voice mode commands
        if chat_id and message.strip().lower() == "/voiceon":
            voice_mode[chat_id] = True
            return "üì¢"  # Megaphone emoji indicates voice mode is on
        if chat_id and message.strip().lower() == "/voiceoff":
            voice_mode[chat_id] = False
            return "üîá"  # Muted speaker emoji indicates voice mode is off

        # –í –≥—Ä—É–ø–ø–∞—Ö –æ—Ç–≤–µ—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –∏–ª–∏ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–≤
        if is_group and not should_reply_in_group(
            message,
            reply_to_bot,
            username=username,
            chat_id=chat_id,
        ):
            return None

        language = None
        try:
            lang_code = detect(message) if message.strip() else ""
            LANG_MAP = {
                "ru": "Russian",
                "en": "English",
                "uk": "Ukrainian",
                "de": "German",
                "fr": "French",
                "es": "Spanish",
            }
            language = LANG_MAP.get(lang_code, "English")
        except LangDetectException:
            language = None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if any(trigger in message.lower() for trigger in TRIGGER_WORDS) or message.startswith("/draw"):
            # –û—á–∏—â–∞–µ–º –∑–∞–ø—Ä–æ—Å –æ—Ç —Ç—Ä–∏–≥–≥–µ—Ä–∞
            if message.startswith("/draw"):
                prompt = message[6:].strip()
            else:
                for trigger in TRIGGER_WORDS:
                    if trigger in message.lower():
                        prompt = message.lower().replace(trigger, "", 1).strip()
                        break
                else:
                    prompt = message
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = await generate_image_async(prompt, chat_id)
            return f"üé® {image_url}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ URL –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
        if "http://" in message or "https://" in message:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
            words = message.split()
            urls = [w for w in words if w.startswith("http://") or w.startswith("https://")]
            if urls:
                url = urls[0]
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    text = await extract_text_from_url_async(url)
                    # –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                    text = summarize_text(text, 1500)
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç URL –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é
                    message += f"\n\nContext from {url}:\n{text}"
                except Exception as e:
                    message += f"\n\n[Failed to retrieve context from {url}: {e}]"
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_prompt = build_system_prompt(
            chat_id=chat_id,
            is_group=is_group,
            message_context=message,
            language=language,
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏
        memory_context = get_memory_context(chat_id)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        context = ""
        try:
            if OPENAI_API_KEY and await is_vector_store_available():
                context_chunks = await semantic_search(message, OPENAI_API_KEY, top_k=3)
                if context_chunks:
                    context = "\n\n".join(context_chunks)
        except Exception as search_error:
            print(f"Semantic search error: {search_error}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        full_prompt = f"{message}\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if memory_context:
            full_prompt = f"Recent conversation:\n{memory_context}\n\nNew message: {full_prompt}"
            
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if context:
            full_prompt += f"--- Context from Configuration ---\n{context}\n\n"
            


        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ –∫ OpenAI –∏–ª–∏ –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏
        # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º Claude –∫–∞–∫ –∞–≤–∞—Ä–∏–π–Ω—ã–π —Ñ–æ–ª–ª–±–µ–∫
        response = await claude_emergency(
            full_prompt,
            system_prompt=system_prompt,
            notify_creator=chat_id==CREATOR_CHAT_ID
        )

        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ –Ω–∞ —á–∞—Å—Ç–∏
        if len(response) > MAX_RESPONSE_LENGTH:
            response_parts = send_long_message(response)
        else:
            response_parts = [response]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        update_memory(chat_id, message, response)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
        log_event({
            "type": "interaction",
            "chat_id": chat_id,
            "username": username,
            "is_group": is_group,
            "message_length": len(message),
            "response_length": len(response),
            "parts": len(response_parts)
        })
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        return response_parts if len(response_parts) > 1 else response_parts[0]
    except Exception as e:
        print(f"Error processing message: {e}")
        log_event({"type": "error", "error": str(e)})
        return "üíé"  # –¢–∏—Ö–∏–π —Å–∏–º–≤–æ–ª –æ—à–∏–±–∫–∏

async def process_file(file_path: str) -> str:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        str: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
    """
    try:
        text = await extract_text_from_file_async(file_path)
        log_event({"type": "file_processed", "path": file_path})
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –µ–≥–æ
        if len(text) > 5000:
            text = f"{text[:2000]}\n\n[... {len(text) - 4000} characters omitted for readability ...]\n\n{text[-2000:]}"
        
        return text
    except Exception as e:
        print(f"Error processing file: {e}")
        log_event({"type": "error", "error": str(e)})
        return f"[Error processing file: {e}]"

# –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
async def auto_reload_core(background_tasks: BackgroundTasks) -> None:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
    
    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
    """
    global core_config, last_check
    
    current_time = time.time()
    if current_time - last_check > CHECK_INTERVAL:
        print("Checking for core configuration updates...")
        new_config = await check_core_json()
        if new_config:
            core_config = new_config
            print("Core configuration updated.")
        last_check = current_time
    
    # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
    background_tasks.add_task(check_wilderness, background_tasks)

async def check_wilderness(background_tasks: BackgroundTasks) -> None:
    """
    –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç wilderness excursion.
    
    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
    """
    global last_wilderness
    
    current_time = time.time()
    hours_since_last = (current_time - last_wilderness) / 3600
    
    if hours_since_last > WILDERNESS_INTERVAL:
        print("Starting scheduled wilderness excursion...")
        await wilderness_excursion()
        last_wilderness = current_time
    
    # Wilderness completed, further checks will be triggered by other requests

# Periodic background loop for configuration and wilderness checks
check_task_started = False

async def periodic_checks_loop() -> None:
    """Runs core and wilderness checks periodically without duplicating tasks."""
    global check_task_started
    if check_task_started:
        return
    check_task_started = True
    while True:
        background = BackgroundTasks()
        await auto_reload_core(background)
        await asyncio.sleep(CHECK_INTERVAL)

# –†–æ—É—Ç—ã
@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞."""
    global core_config, last_check, last_wilderness

    print(f"Starting {AGENT_NAME} Assistant v{VERSION}...")
    core_config = await initialize_config()
    last_check = time.time()
    last_wilderness = time.time()
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—É—Å–∫
    asyncio.create_task(startup_vectorization())
    asyncio.create_task(periodic_checks_loop())

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π –º–∞—Ä—à—Ä—É—Ç —Å –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
    return {
        "name": AGENT_NAME,
        "version": VERSION,
        "status": "operational",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/message", response_model=MessageResponse)
async def handle_message(
    background_tasks: BackgroundTasks,
    request: MessageRequest
) -> MessageResponse:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.
    
    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        request: –î–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        
    Returns:
        MessageResponse: –û—Ç–≤–µ—Ç —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –°–µ–ª–µ—Å—Ç—ã
    """
    message = request.message
    chat_id = request.chat_id
    is_group = request.is_group
    username = request.username
    reply_to_bot = request.reply_to_bot
    
    if not message:
        raise HTTPException(status_code=400, detail="Message is required")
    
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    response = await process_message(
        message,
        chat_id,
        is_group,
        username,
        reply_to_bot=reply_to_bot,
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
    if response is None:
        return MessageResponse(response=None, multi_part=False)
    elif isinstance(response, list):
        return MessageResponse(response_parts=response, multi_part=True)
    else:
        return MessageResponse(response=response, multi_part=False)

async def process_and_send_response(
    message: str,
    chat_id: str,
    is_group: bool,
    username: Optional[str],
    reply_to_bot: bool = False,
    reply_to_message_id: Optional[int] = None,
) -> None:
    """Process a message and send the response via Telegram asynchronously."""
    try:
        if is_group and not should_reply_in_group(
            message,
            reply_to_bot,
            username=username,
            chat_id=chat_id,
        ):
            return

        if is_group:
            await asyncio.sleep(
                GROUP_DELAY_RANGE[0]
                if GROUP_DELAY_RANGE[0] == GROUP_DELAY_RANGE[1]
                else random.uniform(*GROUP_DELAY_RANGE)
            )

        await send_typing(chat_id)
        response = await process_message(
            message,
            chat_id,
            is_group,
            username,
            reply_to_bot=reply_to_bot,
        )

        if response is None:
            return

        if voice_mode.get(chat_id) and message.strip().lower() not in ["/voiceon", "/voiceoff"]:
            text_resp = response if not isinstance(response, list) else "\n\n".join(response)
            voice_file = os.path.join(UPLOADS_DIR, f"reply_{int(time.time())}.mp3")
            await text_to_speech(text_resp, voice_file)
            sent = await send_audio_message(
                chat_id,
                voice_file,
                caption=text_resp,
                reply_to_message_id=reply_to_message_id,
            )
            try:
                os.remove(voice_file)
            except Exception:
                pass
        else:
            if isinstance(response, list):
                sent = await send_multipart_message(chat_id, response, reply_to_message_id=reply_to_message_id)
            else:
                sent = await send_message(chat_id, response, reply_to_message_id)

        if not sent:
            log_event({"type": "send_error", "chat_id": chat_id, "message": "delivery failed"})
    except Exception as e:
        print(f"Error in process_and_send_response: {e}")
        log_event({"type": "send_error", "error": str(e), "chat_id": chat_id})

@app.post("/webhook")
async def webhook(
    request: Request,
    background_tasks: BackgroundTasks
) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–µ–±—Ö—É–∫–∏ –æ—Ç Telegram –∏–ª–∏ –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    
    Args:
        request: –û–±—ä–µ–∫—Ç –∑–∞–ø—Ä–æ—Å–∞
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        
    Returns:
        Dict[str, Any]: –û—Ç–≤–µ—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–µ–±—Ö—É–∫–æ–º
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = await request.json()
        print("Received webhook data")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –ª–∏ Telegram
        if "message" in data:
            chat = data["message"].get("chat", {})
            chat_id = str(chat.get("id"))
            is_group = chat.get("type") in ["group", "supergroup"]
            username = data["message"].get("from", {}).get("username")
            message_id = data["message"].get("message_id")
            if "text" in data["message"]:
                message = data["message"]["text"]
            elif "voice" in data["message"]:
                file_id = data["message"]["voice"]["file_id"]
                temp_path = os.path.join(UPLOADS_DIR, f"{file_id}.ogg")
                downloaded = await download_telegram_file(file_id, temp_path)
                message = await transcribe_audio(downloaded) if downloaded else ""
            else:
                message = ""
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ –∏ —Å—Ä–∞–∑—É –æ—Ç–≤–µ—á–∞–µ–º webhook
            reply_to_bot = False
            if "reply_to_message" in data["message"]:
                orig = data["message"]["reply_to_message"].get("from", {})
                if orig.get("is_bot") and (not BOT_USERNAME or orig.get("username", "").lower() == BOT_USERNAME):
                    reply_to_bot = True

            background_tasks.add_task(
                process_and_send_response,
                message,
                chat_id,
                is_group,
                username,
                reply_to_bot,
                message_id,
            )
            return {"status": "accepted", "chat_id": chat_id}
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        return {"status": "received"}
    except Exception as e:
        print(f"Error handling webhook: {e}")
        log_event({"type": "webhook_error", "error": str(e)})
        return {"status": "error", "error": str(e)}

@app.post("/upload")
async def upload_file(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
) -> Dict[str, str]:
    f"""
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.

    –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {MAX_UPLOAD_SIZE // (1024 * 1024)} MB.

    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        file: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª

    Returns:
        Dict[str, str]: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ
    """
    chunk_size = 1024 * 1024  # 1 MB
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{timestamp}_{file.filename.replace(' ', '_')}"
    file_path = os.path.join(UPLOADS_DIR, safe_filename)

    try:
        content_length = file.headers.get("content-length")
        if content_length and int(content_length) > MAX_UPLOAD_SIZE:
            raise HTTPException(status_code=413, detail="File too large")

        total_size = 0
        with open(file_path, "wb") as f:
            while True:
                chunk = await file.read(chunk_size)
                if not chunk:
                    break
                total_size += len(chunk)
                if total_size > MAX_UPLOAD_SIZE:
                    raise HTTPException(status_code=413, detail="File too large")
                f.write(chunk)

        log_event({"type": "file_uploaded", "filename": safe_filename, "size": total_size})

        return {
            "filename": safe_filename,
            "path": file_path,
            "size": total_size,
            "content_type": file.content_type
        }
    except HTTPException:
        if os.path.exists(file_path):
            os.remove(file_path)
        log_event({"type": "file_upload_error", "error": "File too large"})
        raise
    except Exception as e:
        if os.path.exists(file_path):
            os.remove(file_path)
        print(f"Error uploading file: {e}")
        log_event({"type": "file_upload_error", "error": str(e)})
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/file")
async def handle_file(
    background_tasks: BackgroundTasks,
    request: Dict[str, Any] = Body(...)
) -> Dict[str, str]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã.
    
    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        request: –¢–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É
        
    Returns:
        Dict[str, str]: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
    """
    file_path = request.get("file_path", "")
    
    if not file_path or not os.path.exists(file_path):
        raise HTTPException(status_code=400, detail="Valid file_path is required")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
    content = await process_file(file_path)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
    content_parts = process_text(content, MAX_RESPONSE_LENGTH) if len(content) > MAX_RESPONSE_LENGTH else [content]
    
    if len(content_parts) > 1:
        return {"content_parts": content_parts, "multi_part": True}
    else:
        return {"content": content_parts[0], "multi_part": False}

@app.get("/healthz")
async def healthcheck() -> Dict[str, str]:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.
    
    Returns:
        Dict[str, str]: –°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
    """
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/status")
async def status() -> MessageResponse:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
    
    Returns:
        Dict[str, Any]: –î–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    """
    global core_config, last_check, last_wilderness
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    vector_store_status = "checking..."
    try:
        vector_store_status = "available" if await is_vector_store_available() else "unavailable"
    except Exception:
        vector_store_status = "error"
    
    return {
        "status": "operational",
        "name": AGENT_NAME,
        "version": VERSION,
        "last_core_check": datetime.fromtimestamp(last_check).isoformat(),
        "last_wilderness": datetime.fromtimestamp(last_wilderness).isoformat(),
        "next_wilderness": (datetime.fromtimestamp(last_wilderness) + 
                           timedelta(hours=WILDERNESS_INTERVAL)).isoformat(),
        "config_version": core_config.get("version") if core_config else "unknown",
        "memory_chats": len(memory_cache),
        "vector_store": vector_store_status,
        "openai_api": "configured" if OPENAI_API_KEY else "not configured"
    }

@app.get("/wilderness")
async def trigger_wilderness(
    background_tasks: BackgroundTasks
) -> MessageResponse:
    """
    –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ wilderness excursion.
    
    Args:
        background_tasks: –û–±—ä–µ–∫—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        
    Returns:
        Dict[str, Any]: –†–µ–∑—É–ª—å—Ç–∞—Ç wilderness excursion
    """
    global last_wilderness
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º wilderness excursion
    reflection = await wilderness_excursion()
    last_wilderness = time.time()
    
    if reflection:
        return {
            "status": "success", 
            "reflection": reflection, 
            "next_scheduled": (datetime.fromtimestamp(last_wilderness) + 
                              timedelta(hours=WILDERNESS_INTERVAL)).isoformat()
        }
    else:
        return {"status": "error", "message": "Failed to generate wilderness reflection"}

# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("server:app", host="0.0.0.0", port=PORT, reload=True)
